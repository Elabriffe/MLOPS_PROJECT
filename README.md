
# ğŸ›ï¸ MLOPS_PROJECT â€“ Classification Multimodale de Produits Rakuten

## ğŸ“Œ Description du projet

Cataloguer les produits selon des donnÃ©es diffÃ©rentes (textes et images) est crucial pour les plateformes e-commerce. Cela permet de dÃ©velopper des applications essentielles telles que :

- La recommandation personnalisÃ©e de produits
- La recherche intelligente par similaritÃ© ou contenu
- Lâ€™amÃ©lioration de lâ€™expÃ©rience utilisateur

Dans ce projet, l'objectif est de **prÃ©dire le code type dâ€™un produit** Ã  partir :
- de **donnÃ©es textuelles** (dÃ©signation et description)
- et dâ€™**images** des produits.

> Ce projet sâ€™inscrit dans le cadre du challenge **Rakuten France Multimodal Product Data Classification** :  
> ğŸ“ [https://challengedata.ens.fr/challenges/35](https://challengedata.ens.fr/challenges/35)

## ğŸ‘¥ Client

Le client est **Rakuten France**, plus prÃ©cisÃ©ment les **administrateurs du site Rakuten.fr**, qui souhaitent optimiser la classification de leur catalogue produits.

## âš™ï¸ Aspects spÃ©cifiques du projet

- ğŸ“¦ DÃ©ploiement dâ€™un modÃ¨le de deep learning en production
- âš¡ Garantie de la rapiditÃ© dâ€™exÃ©cution (latence faible en infÃ©rence)
- ğŸ” Traitement multimodal (texte + image)
- ğŸ·ï¸ Classification sur plus de 1000 classes

## ğŸ“š Ressources

- **DonnÃ©es textuelles** (~60 Mo) : dÃ©signation + description
- **DonnÃ©es images** (~2,2 Go) : une image par produit
- **Ensemble de donnÃ©es** : ~99 000 exemples
- ğŸ”— [DonnÃ©es disponibles ici](https://challengedata.ens.fr/challenges/35)

## ğŸ“ Arborescence du projet

```
ğŸ“ MLOPS_PROJECT
â”œâ”€â”€ ğŸ“ .github
â”‚   â””â”€â”€ ğŸ“ workflows
â”œâ”€â”€ ğŸ“ airflow
â”‚   â”œâ”€â”€ ğŸ“ config
â”‚   â”œâ”€â”€ ğŸ“ dags
â”‚   â”‚   â””â”€â”€ ğŸ“ __pycache__
â”‚   â””â”€â”€ ğŸ“ logs
â”‚       â”œâ”€â”€ ğŸ“ dag_processor_manager
â”‚       â””â”€â”€ ğŸ“ scheduler
â”‚           â”œâ”€â”€ ğŸ“ 2025-05-02
â”‚           â”‚   â””â”€â”€ ğŸ“ native_dags
â”‚           â”‚       â””â”€â”€ ğŸ“ example_dags
â”‚           â”‚           â”œâ”€â”€ ğŸ“ plugins
â”‚           â”‚           â””â”€â”€ ğŸ“ subdags
â”‚           â”œâ”€â”€ ğŸ“ 2025-05-03
â”‚           â”‚   â””â”€â”€ ğŸ“ native_dags
â”‚           â”‚       â””â”€â”€ ğŸ“ example_dags
â”‚           â”‚           â”œâ”€â”€ ğŸ“ plugins
â”‚           â”‚           â””â”€â”€ ğŸ“ subdags
â”‚           â””â”€â”€ ğŸ“ 2025-05-04
â”‚               â””â”€â”€ ğŸ“ native_dags
â”‚                   â””â”€â”€ ğŸ“ example_dags
â”‚                       â”œâ”€â”€ ğŸ“ plugins
â”‚                       â””â”€â”€ ğŸ“ subdags
â”œâ”€â”€ ğŸ“ ext
â”‚   â””â”€â”€ ğŸ“ __pycache__
â”œâ”€â”€ ğŸ“ models
â”œâ”€â”€ ğŸ“ references
â”œâ”€â”€ ğŸ“ reports
â”œâ”€â”€ ğŸ“ src
â”‚   â”œâ”€â”€ ğŸ“ data
â”‚   â”‚   â”œâ”€â”€ ğŸ“ models
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ __pycache__
â”‚   â”‚   â””â”€â”€ ğŸ“ processed
â”‚   â”œâ”€â”€ ğŸ“ features
â”‚   â”‚   â””â”€â”€ ğŸ“ __pycache__
â”‚   â”œâ”€â”€ ğŸ“ models
â”‚   â”‚   â””â”€â”€ ğŸ“ __pycache__
â”‚   â””â”€â”€ ğŸ“ visualization
â””â”€â”€ ğŸ“ utils
    â””â”€â”€ ğŸ“ __pycache__
```

## ğŸš€ Objectifs Ã  venir

- âœ… PrÃ©traitement et vectorisation des donnÃ©es textuelles
- âœ… PrÃ©traitement et normalisation des images
- âœ… ModÃ¨le multimodal (texte + image)
- ğŸ”„ EntraÃ®nement et validation
- ğŸŒ DÃ©ploiement (Airflow, FastAPI, Docker, etc.)
- ğŸ“Š Monitoring & MLOps pipeline

## ğŸ“˜ Guide d'installation & utilisation

### ğŸ“¥ Ã‰tape 0 : Cloner le dÃ©pÃ´t Git

```bash
git clone https://url-de-votre-repo/MLOPS_PROJECT.git
cd MLOPS_PROJECT
```

### ğŸ§± Ã‰tape 1 : PrÃ©parer les dossiers de donnÃ©es

Avant tout, crÃ©ez deux dossiers dans le dossier parent du projet pour accueillir les nouvelles donnÃ©es :

```bash
mkdir -p ../NEW_DATA/catalogue
mkdir -p ../NEW_DATA/images
```

**âš ï¸ Important :**  
Respectez la **nomenclature des fichiers** :
- Pour les fichiers CSV, utilisez exactement ces noms :
  - `New_X_train.csv`
  - `New_y_train.csv`

cf screen pour donnÃ©es texte :
![Nomenclature donnÃ©e texte.png](assets/Image_1.png)

cf screen pour donnÃ©es images :
![Donnees images.png](assets/Image_2.png)

#### ğŸ³ Ã‰tape 2 : Construire lâ€™image Docker de lâ€™API

Construisez lâ€™image Docker Ã  partir du Dockerfile spÃ©cifique :

```bash
docker build -f docker/Dockerfile -t mon_projet_mlops:latest .
```

#### âš™ï¸ Ã‰tape 3 : Lancer tous les services avec Docker Compose

DÃ©marrez les services en utilisant **docker-compose.yml** (ne pas utiliser `docker-compose.ci.yml`) :

```bash
docker-compose up --build
```

Tous les services seront lancÃ©s automatiquement (API, base de donnÃ©es, MinIO, etc.).

Vous devriez avoir quelque chose comme ceci :

![Ecran docker compose.png](assets/Image_3.png)

#### ğŸ› ï¸ Ã‰tape 4 : Initialisation de la base de donnÃ©es et du bucket MinIO

Avant d'utiliser l'API, exÃ©cutez ces deux commandes pour initialiser la base PostgreSQL et crÃ©er le bucket MinIO :

```bash
docker exec <nom_conteneur_api> python /app/src/data/create_db_postgre.py
docker exec <nom_conteneur_api> python /app/src/data/create_bucket_minio.py
```

Remplacez `<nom_conteneur_api>` par le nom rÃ©el de votre conteneur (par exemple : `projet_mlops_linux-mlops-api-1`).

#### ğŸŒ AccÃ©der Ã  l'API

Une fois les services lancÃ©s, lâ€™API FastAPI est accessible ici :

ğŸ‘‰ [http://localhost:8000/docs](http://localhost:8000/docs)

(PossibilitÃ© Ã©galement d'utiliser en local, le fichier my_app.py, aprÃ¨s avoir crÃ©Ã© un dossier avec un environnement virtuel contenant streamlit)